{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/Users/alexandruparaschiv/Desktop/cell_images/processed_data/first_train'\n",
    "TEST_DIR = '/Users/alexandruparaschiv/Desktop/cell_images/processed_data/first_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [   transforms.Resize(size=(64,64)),\n",
    "        transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = TRAIN_DIR\n",
    "dataset = ImageFolderWithPaths(data_dir,transform=transform) # our custom dataset\n",
    "train_data = torch.utils.data.DataLoader(dataset,shuffle=True)\n",
    "train_data_loader = train_data\n",
    "\n",
    "\n",
    "data_dir = TEST_DIR\n",
    "dataset = ImageFolderWithPaths(data_dir,transform=transform) # our custom dataset\n",
    "test_data = torch.utils.data.DataLoader(dataset,shuffle=True)\n",
    "test_data_loader = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 13*13, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.dropout(x)\n",
    "        x = x.view(1, 16*13*13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x=self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x=self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x=self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.6)\n",
    "classes = ['parazitized','uninfected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.678\n",
      "[1,  4000] loss: 0.662\n",
      "[1,  6000] loss: 0.655\n",
      "[1,  8000] loss: 0.654\n",
      "[1, 10000] loss: 0.624\n",
      "[1, 12000] loss: 0.644\n",
      "[1, 14000] loss: 0.635\n",
      "[1, 16000] loss: 0.618\n",
      "[1, 18000] loss: 0.586\n",
      "[2,  2000] loss: 0.581\n",
      "[2,  4000] loss: 0.512\n",
      "[2,  6000] loss: 0.370\n",
      "[2,  8000] loss: 0.267\n",
      "[2, 10000] loss: 0.250\n",
      "[2, 12000] loss: 0.212\n",
      "[2, 14000] loss: 0.222\n",
      "[2, 16000] loss: 0.224\n",
      "[2, 18000] loss: 0.214\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_data_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels, path = data\n",
    "\n",
    "        match = re.search(\"uninfected\", path[0])\n",
    "        if not match:\n",
    "            labels[0] = 0\n",
    "        elif match:\n",
    "            labels[0] = 1\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        #print(i,loss)\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0.9233632581563389\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "true_pred = 0\n",
    "for i, data in enumerate(test_data_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels, path = data\n",
    "\n",
    "\n",
    "        match = re.search(\"uninfected\", path[0])\n",
    "        if not match:\n",
    "            labels[0]= 0\n",
    "        elif match:\n",
    "            labels[0]= 1\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        preds = np.squeeze(predicted.numpy())\n",
    "\n",
    "        if preds == labels[0].numpy():\n",
    "            true_pred +=1\n",
    "        counter += 1\n",
    "print(\"Accuracy of {}\".format(true_pred/counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
